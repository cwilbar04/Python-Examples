{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\setlength{\\parindent}{0pt}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christopher Wilbar   \n",
    "MSDS_422-DL_SEC55    \n",
    "Assignment 7: Image Processing With a CNN    \n",
    "Kaggle Display Name: Chris Wilbar   \n",
    "Kaggle User Name: cwilbar  \n",
    "Kaggle User ID: 538226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summary and Problem Definition  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Definition:**   \n",
    "Benchmark experiment is conducted to evaluate deep learning CNN methodology for cat vs. dog image recognition. Training is performmed on dataset from kaggle competition: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition. In this analysis I test 4 different models, in a 2x2 design, modifying the number of Convolutional Layers and Fully Connected Layers. We are most concerned about achieving the highest possible accuracy in image classification so I explore if we should be willing to sacrifice training time for model accuracy and what type of machine learning model works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "**Summary**:   \n",
    "\n",
    "Finding parameters that didn't simply predict dog for all images proved difficult. Finally was able to create a model that suggested the Convolutional Layers were the most important for increasing accuracy, and in this case, utilizing as many as possible proved fruitful, while additional fully connected layers actually were detrimental. Current belief is the convolutional neural networks are definitely to be preferred for image classification tasks as the most closely resemeble human vision and are better able to break down complex images, while saving some computational power. Given enough time and processing power, the higher definition images likely would produce better results by allowing more convolutional layers that can catch even more subtlties. A network utitilzing as many convoulutional 2D layers, combined with maximum pooling and a sigmoid final activation function worked well here though further analysis should be taken to see if average pooling or different activation or optimization functions might produce even better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Experiment: Scikit Learn Artificial Neural Networks\n",
    "\n",
    "#                Name  Conv2d Layers  Fully Connected Layers  Processing Time  \\\n",
    "# 0  CNN-2Conv2D-2FCN              2                       1       117.452718   \n",
    "# 1  CNN-2Conv2D-5FCN              2                       4       117.349712   \n",
    "# 2  CNN-4Conv2D-5FCN              4                       1       152.023695   \n",
    "# 3  CNN-4Conv2D-5FCN              4                       4       151.666675   \n",
    "\n",
    "#    Training Set Accuracy  Validation Set Accuracy  Test Log Loss - Kaggle  \n",
    "# 0               0.603840                  0.59712                 0.71938  \n",
    "# 1               0.677120                  0.68176                 0.64015  \n",
    "# 2               0.709013                  0.71184                 0.57781  \n",
    "# 3               0.555947                  0.55472                 0.68306  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Results and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results and Recomendations** \n",
    "\n",
    "CNN should be pursued whenever possible for image classification, time is needed to tune the many available options.\n",
    "\n",
    "Focus should be on getting the highest quality images possible and getting as many convolutional layers as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Research Design and Methods Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research Design**   \n",
    "\n",
    "Labelled iamges provided through Kaggle competition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methods Used**  \n",
    "Pyhton v.3 Jupyter Notebook was created to perform the analysis.\n",
    "The following packages were used:\n",
    "pandas, numpy, matplotlip.pyplot, seaborn, sklearn, os, cv2, tensorflow, keras\n",
    "  \n",
    "Basic pyhton descriptive statisitcs were generated. \n",
    "Because the response variable was one of 2 classes, binary classification methods are appropriate.\n",
    "\n",
    "Tensorflow learn with Keras was the primary tool for analysis.\n",
    "\n",
    "Convolutional Neural Network using relu, sigmoid, and rmsprop was created using Keras in Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Programming Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 | Initial Setup and Preliminary Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# seed value for random number generators to obtain reproducible results\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "import os # operating system functions, shutil # high-level file operations\n",
    "import os.path  # for manipulation of file path names\n",
    "\n",
    "# import base packages into the namespace for this program\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import seaborn as \n",
    "import matplotlib as mpl #image display\n",
    "from time import time #time tracking\n",
    "import matplotlib.pyplot as plt  #plots\n",
    "#from matplotlib import rc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import cv2  # Open CV for image processing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(RANDOM_SEED)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make output stable across runs\n",
    "def reset_graph(seed= RANDOM_SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will work with 64x64 color images at least to start\n",
    "def parse_color_and_resize(image_file_path, size = (64, 64)):\n",
    "    image = cv2.imread(image_file_path, cv2.IMREAD_COLOR)\n",
    "    # Default cv2 is BGR... need RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, size)\n",
    "    return(image) \n",
    "\n",
    "def show_color_image(image):\n",
    "    plt.imshow(image) \n",
    "    plt.axis('off')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inital Setup to Create Npy Files- Skip after first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #First we need to convert jpg images to numpy array to use in tensorflow\n",
    "\n",
    "# train_image_dir_name = \\\n",
    "#     'C:\\\\Users\\\\nm179525\\\\Desktop\\\\Practical_Machine_Learning\\\\Assignment7\\\\dogs-vs-cats-redux-kernels-edition\\\\train\\\\train'\n",
    "\n",
    "# test_image_dir_name = \\\n",
    "#     'C:\\\\Users\\\\nm179525\\\\Desktop\\\\Practical_Machine_Learning\\\\Assignment7\\\\dogs-vs-cats-redux-kernels-edition\\\\test\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \"Human\" sorting of file names facilitated by\n",
    "# # https://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "# import re\n",
    "\n",
    "# def tryint(s):\n",
    "#     try:\n",
    "#         return int(s)\n",
    "#     except:\n",
    "#         return s\n",
    "\n",
    "# def alphanum_key(s):\n",
    "#     \"\"\" Turn a string into a list of string and number chunks.\n",
    "#         \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "#     \"\"\"\n",
    "#     return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "# def sort_nicely(l):\n",
    "#     \"\"\" Sort the given list in the way that humans expect.\n",
    "#     \"\"\"\n",
    "#     l.sort(key=alphanum_key)\n",
    "    \n",
    "# # Generate nicely sorted list of file names, excluding hidden files    \n",
    "# def directory_list (dir_name):\n",
    "#     start_list = os.listdir(dir_name)\n",
    "#     end_list = []\n",
    "#     for file in start_list:\n",
    "#         if (not file.startswith('.')):\n",
    "#             end_list.append(file) \n",
    "#     end_list.sort(key = alphanum_key)        \n",
    "#     return(end_list)        \n",
    "\n",
    "# train_file_names = directory_list(train_image_dir_name)\n",
    "# test_file_names = directory_list(test_image_dir_name)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check random images\n",
    "# image_file_path = os.path.join(train_image_dir_name, train_file_names[125])  \n",
    "\n",
    "# #Check first image\n",
    "# # Work with resized color image using default size 64x64    \n",
    "# image = parse_color_and_resize(image_file_path, size=(64, 64))\n",
    "# show_color_image(image)\n",
    "# image.shape  # shows size of the numpy array  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_file_path = os.path.join(train_image_dir_name, train_file_names[12499])  \n",
    "\n",
    "# #Check first image\n",
    "# # Work with resized color image using default size 64x64    \n",
    "# image = parse_color_and_resize(image_file_path)\n",
    "# show_color_image(image)\n",
    "# image.shape  # shows size of the numpy array  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_file_path = os.path.join(test_image_dir_name, test_file_names[130])  \n",
    "\n",
    "# #Check first image\n",
    "# # Work with resized color image using default size 64x64    \n",
    "# image = parse_color_and_resize(image_file_path)\n",
    "# show_color_image(image)\n",
    "# image.shape  # shows size of the numpy array  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This code ran once to create and save image data as np array\n",
    "\n",
    "# print('\\nProcessing train image files to 64x64 color array')\n",
    "# train_data = np.zeros((len(train_file_names), 128, 128, 3))  \n",
    "# for ifile in range(len(train_file_names)):\n",
    "#     image_file_path = os.path.join(train_image_dir_name, train_file_names[ifile])\n",
    "#     image = parse_color_and_resize(image_file_path, size = (128, 128))\n",
    "#     train_data[ifile,:,:,:] = image\n",
    "\n",
    "# print('\\nProcessing test image files to 64x64 color array')\n",
    "# test_data = np.zeros((len(test_file_names), 128, 128, 3))  \n",
    "# for ifile in range(len(test_file_names)):\n",
    "#     image_file_path = os.path.join(test_image_dir_name, test_file_names[ifile])\n",
    "#     image = parse_color_and_resize(image_file_path, size = (128, 128))\n",
    "#     test_data[ifile,:,:,:] = image\n",
    "\n",
    "# # We now save the files as npy binary format to call for later use\n",
    "\n",
    "# # Documentation on npy binary format for saving numpy arrays for later use\n",
    "# #     https://towardsdatascience.com/\n",
    "# #             why-you-should-start-using-npy-file-more-often-df2a13cc0161 \n",
    "    \n",
    "# # The directory where we store the numpy array objects\n",
    "# # store our smaller dataset\n",
    "\n",
    "# outdir = 'C:\\\\Users\\\\nm179525\\\\Desktop\\\\Practical_Machine_Learning\\\\Assignment7'\n",
    "# #os.mkdir(outdir)    \n",
    "       \n",
    "# np.save(os.path.join(outdir, 'train_25000_128_128_3.npy'), train_data)\n",
    "# np.save(os.path.join(outdir, 'test_12500_128_128_3.npy'), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1b | Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data saved previously\n",
    "train_data = np.load('train_25000_64_64_3.npy')\n",
    "test_data = np.load('test_12500_64_64_3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 64, 64, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 64, 64, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the y variable. We know we are given 12500 cats (0) followed by 12500 dogs (1)\n",
    "y_train_all = np.concatenate((np.zeros((12500), dtype = np.int32), \n",
    "                      np.ones((12500), dtype = np.int32)), axis = 0).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm it still looks good. Need to cast as int to use the show_color_image function for 0-255 data\n",
    "def show_color_image(image):\n",
    "    plt.imshow(image) \n",
    "    plt.axis('off')\n",
    "    plt.show()   \n",
    "\n",
    "train_image = int(time())%10000\n",
    "show_color_image(train_data[train_image,:,:,:].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = int(time())%10000\n",
    "show_color_image(test_data[test_image,:,:,:].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data /= 255\n",
    "test_data /= 255\n",
    "\n",
    "#y_train_all = keras_y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color_image(train_data[train_image,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color_image(test_data[test_image,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data,y_train_all,test_size=0.25, random_state=RANDOM_SEED, stratify=y_train_all, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proportion of dogs in y_train : ', y_train.sum()/y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proportion of dogs in y_val : ', y_val.sum()/y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the set up\n",
    "names = ('CNN-2Conv2D-2FCN',\n",
    "        'CNN-2Conv2D-5FCN',\n",
    "        'CNN-4Conv2D-5FCN',\n",
    "        'CNN-4Conv2D-5FCN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Variables that will be needed\n",
    "batch_size = 100\n",
    "epochs = 5\n",
    "conv2Dnodes = [4,4,4,4]\n",
    "fclayers = [1,3,5,7]\n",
    "startfilters = 32\n",
    "nodesperlayer = 10\n",
    "\n",
    "processingtime = np.zeros(4)\n",
    "train_accuracy = np.zeros(4)\n",
    "validation_accuracy = np.zeros(4)\n",
    "test_accuracy = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for model to easily change parameters\n",
    "def catdog(conv2Dnodes,startfilters, fclayers, nodesperlayer):\n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(startfilters, (2,2), input_shape=train_data.shape[1:], activation='relu',data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "    \n",
    "    for i in range(int(conv2Dnodes)-1):\n",
    "        startfilters *=2\n",
    "        model.add(Conv2D(startfilters, (2,2), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        i +=1 \n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for j in range(fclayers):\n",
    "        model.add(Dense(nodesperlayer, activation='relu'))\n",
    "        model.add(Dropout(rate=0.5))\n",
    "        j += 1\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def catdog(conv2Dnodes,startfilters, fclayers, nodesperlayer):\n",
    "     \n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv2D(startfilters, (2,2), padding='same', input_shape=train_data.shape[1:], activation='relu',data_format=\"channels_last\"))\n",
    "#     model.add(Conv2D(startfilters, (2,2), activation='relu',data_format=\"channels_last\"))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", padding=\"same\")) \n",
    "    \n",
    "#     for i in range(int(conv2Dnodes/2)-1):\n",
    "#         startfilters *=2\n",
    "#         model.add(Conv2D(startfilters, (2,2), padding = 'same', activation='relu',data_format=\"channels_last\"))\n",
    "#         model.add(Conv2D(startfilters, (2,2), activation='relu',data_format=\"channels_last\"))\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\", padding=\"same\"))\n",
    "#         model.add(Dropout(rate=0.5))\n",
    "#         i +=1 \n",
    "\n",
    "#     model.add(Flatten())\n",
    "    \n",
    "#     for j in range(fclayers):\n",
    "#         model.add(Dense(nodesperlayer, activation='relu'))\n",
    "#         model.add(Dropout(rate=0.5))\n",
    "#         j += 1\n",
    "\n",
    "#     model.add(Dense(1, activation='softmax')) \n",
    "\n",
    "#     model.compile(optimizer=\"rmsprop\", loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = catdog(conv2Dnodes[0],startfilters,fclayers[0],nodesperlayer)\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "history = model0.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val,y_val), verbose=1, shuffle=True)\n",
    "end_time = time()\n",
    "runtime = end_time - start_time  # seconds of wall-clock time \n",
    "processingtime[0] = runtime\n",
    "print(\"\\nProcessing time (seconds): %f\" % runtime)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0 = model0.predict_proba(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy[0] = model0.evaluate(X_train,y_train)[1]\n",
    "validation_accuracy[0] = model0.evaluate(X_val,y_val)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle submission preparation:\n",
    "dataframe0 = pd.DataFrame({\"id\": list(range(1,len(predictions0)+1)), \"label\": predictions0[:,0]})\n",
    "dataframe0.to_csv('output_2_2.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "K.reset_uids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = catdog(conv2Dnodes[1],startfilters,fclayers[1],nodesperlayer)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "history = model1.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val,y_val), verbose=1, shuffle=True)\n",
    "end_time = time()\n",
    "runtime = end_time - start_time  # seconds of wall-clock time \n",
    "processingtime[1] = runtime\n",
    "print(\"\\nProcessing time (seconds): %f\" % runtime)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model1.predict_proba(test_data, verbose=1)\n",
    "train_accuracy[1] = model1.evaluate(X_train,y_train)[1]\n",
    "validation_accuracy[1] = model1.evaluate(X_val,y_val)[1]\n",
    "dataframe1 = pd.DataFrame({\"id\": list(range(1,len(predictions1)+1)), \"label\": predictions1[:,0]})\n",
    "dataframe1.to_csv('output_2_5.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "K.reset_uids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = catdog(conv2Dnodes[2],startfilters,fclayers[2],nodesperlayer)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "history = model2.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val,y_val), verbose=1, shuffle=True)\n",
    "end_time = time()\n",
    "runtime = end_time - start_time  # seconds of wall-clock time \n",
    "processingtime[2] = runtime\n",
    "print(\"\\nProcessing time (seconds): %f\" % runtime)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.predict_proba(test_data, verbose=1)\n",
    "train_accuracy[2] = model2.evaluate(X_train,y_train)[1]\n",
    "validation_accuracy[2] = model2.evaluate(X_val,y_val)[1]\n",
    "dataframe2 = pd.DataFrame({\"id\": list(range(1,len(predictions2)+1)), \"label\": predictions2[:,0]})\n",
    "dataframe2.to_csv('output_4_2.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "K.reset_uids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = catdog(conv2Dnodes[3],startfilters,fclayers[3],nodesperlayer)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "history = model3.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val,y_val), verbose=1, shuffle=True)\n",
    "end_time = time()\n",
    "runtime = end_time - start_time  # seconds of wall-clock time \n",
    "processingtime[3] = runtime\n",
    "print(\"\\nProcessing time (seconds): %f\" % runtime)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = model3.predict_proba(test_data, verbose=1)\n",
    "train_accuracy[3] = model3.evaluate(X_train,y_train)[1]\n",
    "validation_accuracy[3] = model3.evaluate(X_val,y_val)[1]\n",
    "dataframe3 = pd.DataFrame({\"id\": list(range(1,len(predictions3)+1)), \"label\": predictions3[:,0]})\n",
    "dataframe3.to_csv('output_4_5.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle Submission Results\n",
    "test_log_loss = (0.71938,0.64015,0.57781,0.68306)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict  \n",
    "\n",
    "results = pd.DataFrame(OrderedDict([('Name', names),\n",
    "                        ('Conv2d Layers', conv2Dnodes),\n",
    "                        ('Fully Connected Layers', fclayers),\n",
    "                        ('Processing Time', processingtime),\n",
    "                        ('Training Set Accuracy', train_accuracy),\n",
    "                        ('Validation Set Accuracy', validation_accuracy),\n",
    "                        ('Test Log Loss - Kaggle', test_log_loss)]))\n",
    "\n",
    "print('\\nBenchmark Experiment: Scikit Learn Artificial Neural Networks\\n')\n",
    "print(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

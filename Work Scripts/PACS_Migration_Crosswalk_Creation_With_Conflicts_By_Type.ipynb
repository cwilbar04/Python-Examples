{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setup packages and sqlite connection\n",
    "import sqlite3 as sq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "cnx = sq.connect('test.db')\n",
    "cur = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check tables active in the DB\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "cur.fetchall()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Time DB Creation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Begin here only if need to update the DB files\n",
    "#Read CSV File in to temp dataframe and check shape\n",
    "tempdf = pd.read_csv(\"pacs2studylevelcheck.csv\")\n",
    "tempdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check it looks as exepected\n",
    "tempdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write to database for easier startup in the future\n",
    "#Replace databasename and write rules (currently replaces what is there) as needed\n",
    "tempdf.to_sql('pacs1premigrationcheck', cnx, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check tables active in the DB\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "cur.fetchall()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Start here if sql database already setup\n",
    "#Read database in to pandas dataframe and check shape\n",
    "df = pd.read_sql_query(\"\"\"SELECT * FROM pacs1premigrationcheck;\"\"\", cnx)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check it looks as expected\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean-up Data\n",
    "df.replace(np.NaN,'NONE',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort Data to get information with most images in pacs2\n",
    "df.sort_values(['NUM_OBJECTS_STUDY_PACS2'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use for Deidentified Data\n",
    "#Remove duplicate suid to get to Study-Level Analysis\n",
    "dfdeidentified = df.drop(['PATIENT_ID_PACS2','patID','ST_PATIENT_ID','ACCESSION_NUMBER_PACS2','ST_ACCESSIONNUMBER','STUDY_DATE_PACS2', 'studydate', 'ST_DATE', 'STUDY_DESCRIPTION_PACS2', 'PATIENT_NAME_PACS2','PT_DICOMFAMILYNAMECOMPLEX'], axis=1)\n",
    "df1 = dfdeidentified.drop_duplicates(subset='suid',keep='first').copy()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use for Non-Deidentified Data\n",
    "#Remove duplicate suid to get to Study-Level Analysis\n",
    "df1 = df.drop_duplicates(subset='suid',keep='first').copy()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['INSTITUTIONAL_DEPARTMENT_NAME_PACS2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['PATIENT_ID_PACS2'] = df1['PATIENT_ID_PACS2'].astype(str)\n",
    "\n",
    "#df['id']= df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[679981,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['PATIENT_ID_PACS2'].apply(lambda x: len(x) !=12)]\n",
    "\n",
    "#df['names'].apply(lambda x: len(x)>1) &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data from pacs1\n",
    "#Set PK from pacs1 (PAT_ID) as Index\n",
    "dfpatientextract = pd.read_csv('pacs1patientextract05012019.csv' \n",
    "                               ,header=0\n",
    "                               ,converters={'pacs1_MRN':str, 'pacs1_MRN_9_Digits':str, 'pacs1_MRN_12_Digits':str, 'pacs1_DOB':str}\n",
    "                               ,index_col = 'pacs1_PAT_ID'\n",
    "                               ,parse_dates=['pacs1_DOB'], date_parser = lambda d: pd.to_datetime(d, format = '%Y%m%d', errors='coerce')\n",
    "                               )\n",
    "dfpatientextract.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dfpatientextract.info())\n",
    "dfpatientextract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Crosswalk data from EDW team, sheet by sheet\n",
    "dfcurrentmrnmatch = pd.read_excel('pacs1_Mapping.xlsx'\n",
    "                                  ,sheet_name = 'Current MRN mapping'\n",
    "                                  ,header=0\n",
    "                                  ,index_col = 'PAT_ID'\n",
    "                                  ,usecols = ['PAT_ID', 'Clarity_MRN','Clarity_PAT_NAME','Clarity_DOB','Clarity_SEX']\n",
    "                                #  ,names = ['Mapped_MRN','Clarity_PAT_NAME','Clarity_DOB','Mapped_Gender']\n",
    "                                  ,converters={'Clarity_MRN':str}\n",
    "                                # ,parse_dates=['Clarity_DOB'], date_parser = lambda d: pd.Series.dt.strftime(d, format=\"%Y%m%d\")\n",
    "                                 )\n",
    "\n",
    "dfcurrentmrnmatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhistoricalmrnmatch = pd.read_excel('pacs1_Mapping.xlsx'\n",
    "                                  ,sheet_name = 'Historical MRN Mapping'\n",
    "                                  ,header=0\n",
    "                                  ,index_col = 'PAT_ID'\n",
    "                                  ,usecols = ['PAT_ID', 'Clarity_New_MRN_2','Clarity_PAT_NAME','CLARITY_DOB','Clarity_SEX']\n",
    "                                 # ,names = ['PAT_ID','Mapped_MRN','Clarity_PAT_NAME','Clarity_DOB','Mapped_Gender']\n",
    "                                  ,converters={'Clarity_New_MRN_2':str}\n",
    "                                # ,parse_dates=['Clarity_DOB'], date_parser = lambda d: pd.Series.dt.strftime(d, format=\"%Y%m%d\")\n",
    "                                 )\n",
    "\n",
    "dfhistoricalmrnmatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfcurrentmrnmatch.info())\n",
    "dfcurrentmrnmatch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfhistoricalmrnmatch.info())\n",
    "dfhistoricalmrnmatch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcurrentmrnmatch.rename(columns={'Clarity_MRN':'Mapped_MRN'},inplace=True)\n",
    "dfhistoricalmrnmatch.rename(columns={'Clarity_New_MRN_2':'Mapped_MRN','CLARITY_DOB':'Clarity_DOB'}, inplace=True)\n",
    "dfpremapping = dfcurrentmrnmatch.append(dfhistoricalmrnmatch)\n",
    "dfpremapping.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpremapping[['Mapping_Last_Name','Mapping_First_Name']] = dfpremapping.Clarity_PAT_NAME.str.split(\",\",expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfpremapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmapping = dfpatientextract.join(dfpremapping, how='left')\n",
    "dfmapping.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfmapping.info())\n",
    "dfmapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmapping.iloc[1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhasmapping = dfmapping[~dfmapping['Mapped_MRN'].isnull()].copy()\n",
    "dfhasmapping.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhasmapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhasmapping['Conflicts'] = 0\n",
    "dfhasmapping['Conflict_Type'] = ''\n",
    "for i in range(0,len(dfhasmapping)):\n",
    "   #Last Names don't match \n",
    "    if dfhasmapping.iloc[i,3] != dfhasmapping.iloc[i,12]:\n",
    "        dfhasmapping.iloc[i,14] += 1   #Increase conflict count by one\n",
    "        dfhasmapping.iloc[i,15] += 'L' #Add L as a conflict type\n",
    "   #First Names don't match \n",
    "    if dfhasmapping.iloc[i,4] != dfhasmapping.iloc[i,13]: \n",
    "        dfhasmapping.iloc[i,14] += 1   #Increase conflict count by one\n",
    "        dfhasmapping.iloc[i,15] += 'F' #Add F as a conflict type\n",
    "   #Gender doesn't match \n",
    "    if dfhasmapping.iloc[i,6] != dfhasmapping.iloc[i,11]: \n",
    "        dfhasmapping.iloc[i,14] += 1   #Increase conflict count by one\n",
    "        if dfhasmapping.iloc[i,6] is None or dfhasmapping.iloc[i,6]=='MISSING' or dfhasmapping.iloc[i,6]=='':\n",
    "            dfhasmapping.iloc[i,15] += 'NG' #Add NG as a conflict type  \n",
    "        else:\n",
    "            dfhasmapping.iloc[i,15] += 'G' #Add G as a conflict type         \n",
    "   #DOB doesn't match \n",
    "    if dfhasmapping.iloc[i,7] != dfhasmapping.iloc[i,10]:\n",
    "        dfhasmapping.iloc[i,14] += 1  #Increase conflict count by one\n",
    "        if dfhasmapping.iloc[i,7] is None or dfhasmapping.iloc[i,7]=='MISSING' or dfhasmapping.iloc[i,7] =='':\n",
    "            dfhasmapping.iloc[i,15] += 'ND' #Add D as a conflict type  \n",
    "        else:\n",
    "            dfhasmapping.iloc[i,15] += 'D' #Add D as a conflict type  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Conflict Counts :\\n', dfhasmapping.Conflicts.value_counts(dropna=False))\n",
    "print('\\nConflict Counts by Type : \\n', dfhasmapping.Conflict_Type.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhasmapping.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfperfectmatch = dfhasmapping.loc[:,['pacs1_MRN','Mapped_MRN','pacs1_Last_Name','Mapping_Last_Name','pacs1_First_Name','Mapping_First_Name']][dfhasmapping['Conflicts']==0]\n",
    "dfperfectmatch.to_csv(\"C:\\\\Users\\\\username\\\\Desktop\\\\pacs1perfectmatch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconflicts = dfhasmapping[dfhasmapping['Conflicts']>0]\n",
    "dfconflicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconflicts.loc[:,['pacs1_MRN','Mapped_MRN','pacs1_Last_Name','Mapping_Last_Name','pacs1_First_Name','Mapping_First_Name','pacs1_Gender','Clarity_SEX','pacs1_DOB','Clarity_DOB']][dfconflicts['Conflict_Type']=='LFGD']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
